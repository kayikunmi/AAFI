# AAFI

COSC- 254 Data Mining

Alternate Algorithims for Frequent Itemsets

Initially, the ***Datasets folder*** contains the following compressed datasets: chess.dat.gz, retail.dat.gz, connect.dat.gz, and mushroom.dat.gz. Running ***convert.py*** generates:

* chess_horizontal.dat and chess_vertical.dat
* retail_horizontal.dat and retail_vertical.dat
* connect_horizontal.dat and connect_vertical.dat
* mushroom_horizontal.dat and mushroom_vertical.dat

*_horizontal.dat → Used for Apriori while _vertical.dat → Used for Eclat & dEclat.*

**APRIORI:**

* File: `apriori.py` (Python) or `Apriori.java` (Java)
* Requires horizontal format files (`_horizontal.dat`)
* Uses candidate generation and pruning to find frequent itemsets
* Logs performance:* Load time
  * Mining time
  * Rule generation time
  * Peak memory (via `tracemalloc`)
  * Total transactions processed
* Usage: python apriori.py Datasets/`<dataset>`_horizontal.dat `<support>`
* Results saved to: `Results/<dataset>_apriori_<minsup>_output.txt`

**ECLAT:**

* File: `eclat.py` (Python)
* Uses a recursive bottom-up traversal of the itemset lattice with frequent itemsets being generated by intersecting tid-lists of all distinct pairs of atoms and checking the cardinality of the resulting tid-list.
* Parses vertical format lines like: `item: tid1,tid2,..`
* Logs performance:
  * Load time
  * Mining time
  * Rule generation time
  * Peak memory (via `tracemalloc`)
  * Total transactions processed
* Usage: python eclat.py Datasets/`<dataset>`_vertical.dat `<minsup>`
* Results saved to: `Results/<dataset>_eclat_<minsup>_output.txt`

**DECLAT:**

* File: `dEclat.py` (Python)
* Uses a recursive bottom-up traversal of the subset tree with frequent itemsets being generated by computing diffsets for all distinct pairs of itemsets and checking the support of the resulting itemset.
* Parses vertical format lines like: `item: tid1,tid2,..`
* Logs performance:
  * Load time
  * Mining time
  * Rule generation time
  * Peak memory (via `tracemalloc`)
  * Total transactions processed
* Usage: python dEclat.py Datasets/`<dataset>`_vertical.dat `<minsup>`
* Results saved to: `Results/<dataset>_dEclat_<minsup>_output.txt`

**Gitignore:**

* Results/mushroom_horizontal_apriori_1500_output.txt

*Folder Structure:*

.

├── Apriori.java

├── apriori.py

├── convert.py

├── eclat.py

├── README.md

├── Datasets/

│   ├── chess.dat.gz

│   ├── chess_horizontal.dat

│   ├── chess_vertical.dat

│   ├── connect.dat.gz

│   ├── connect_horizontal.dat

│   ├── connect_vertical.dat

│   ├── mushroom.dat.gz

│   ├── mushroom_horizontal.dat

│   ├── mushroom_vertical.dat

│   ├── retail.dat.gz

│   ├── retail_horizontal.dat

│   └── retail_vertical.dat

└── Results/

3 directories, 18 files


We attempted to run the original `apriori.py` on the `chess_horizontal.dat` dataset with minimum supports of 1000 and 1500. However, due to the dataset's high density and the exponential candidate generation in Apriori, both runs failed to complete within a reasonable time frame (exceeding 8 hours on a MacBook Air M1 with 8GB RAM). This highlights a known limitation of the Apriori algorithm on dense datasets with low support thresholds.
